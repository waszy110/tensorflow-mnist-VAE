{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mnist_data\n",
    "import os\n",
    "# import beta_vae as vae\n",
    "import vae\n",
    "import plot_utils\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#不平衡 类别\n",
    "choose_c=3\n",
    "#图像尺寸\n",
    "IMAGE_SIZE_MNIST = 28\n",
    "#隐变量维度\n",
    "dim_z=3\n",
    "#alpha classification loss balance\n",
    "alpha=400\n",
    "#隐层节点数\n",
    "n_hidden=500\n",
    "#学习率\n",
    "learn_rate=1e-3\n",
    "#训练轮数\n",
    "n_epochs=100\n",
    "#批量数目\n",
    "batch_size=256\n",
    "#标签样式 one-hot编码\n",
    "one_hot=np.eye(10)\n",
    "np.random.seed(100)\n",
    "dim_img=28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 10:13:35.522911 139796854155072 deprecation_wrapper.py:119] From /home/yuemei.zhu/tensorflow-mnist-VAE/mnist_data.py:30: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "_, _, _, _, test_data, test_labels = mnist_data.prepare_MNIST_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = tf.placeholder(tf.float32, shape=[None, dim_img], name='input_img')\n",
    "x_label = tf.placeholder(tf.float32, shape=[None, 10], name='img_label')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rebanlance_data=np.load('./train_rebanlance_data.npy')\n",
    "np.random.shuffle(train_rebanlance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类器结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 10:13:37.122785 139796854155072 deprecation.py:323] From <ipython-input-6-d38760c62036>:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0918 10:13:37.127774 139796854155072 deprecation.py:506] From /home/yuemei.zhu/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0918 10:13:37.315846 139796854155072 deprecation.py:323] From <ipython-input-6-d38760c62036>:13: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0918 10:13:37.441100 139796854155072 deprecation.py:323] From <ipython-input-6-d38760c62036>:26: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0918 10:13:37.685164 139796854155072 deprecation.py:506] From <ipython-input-6-d38760c62036>:27: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0918 10:13:37.710959 139796854155072 deprecation.py:323] From <ipython-input-6-d38760c62036>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CNN 的模型函数\"\"\"\n",
    "# 输入层\n",
    "input_layer = tf.reshape(x_hat, [-1, 28, 28, 1])\n",
    "# 第一个卷积层\n",
    "conv1 = tf.layers.conv2d(\n",
    "  inputs=input_layer,\n",
    "  filters=32,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  activation=tf.nn.relu)\n",
    "\n",
    "# 第一个池化层\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# 第二个卷积层和池化层\n",
    "conv2 = tf.layers.conv2d(\n",
    "  inputs=pool1,\n",
    "  filters=64,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "# 全连接层\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout=tf.nn.dropout(dense, keep_prob)\n",
    "# dropout = tf.layers.dropout(\n",
    "#   inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "# Logits 层\n",
    "logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "# predicts=tf.argmax(logits,axis=1)\n",
    "# 计算损失（可用于`训练`和`评价`中）\n",
    "cls_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=x_label, logits=logits))\n",
    "cls_optm = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "cls_train_op = cls_optm.minimize(cls_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在类别重新均衡的数据集上训练分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_epochs=100\n",
    "cls_batch_size=128\n",
    "batchs=int(train_rebanlance_data.shape[0]/cls_batch_size)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={keep_prob : 0.9})\n",
    "for epoch in range(cls_epochs):\n",
    "    loss_np=0\n",
    "    for i in range(batchs):\n",
    "        batch_xs_input=train_rebanlance_data[i*cls_batch_size:(i+1)*cls_batch_size,:-10]\n",
    "        batch_xs_label=train_rebanlance_data[i*cls_batch_size:(i+1)*cls_batch_size,-10:]\n",
    "        _, cls_loss_np= sess.run(\n",
    "            (cls_train_op, cls_loss),\n",
    "            feed_dict={x_hat: batch_xs_input,x_label:batch_xs_label,keep_prob : 0.9})\n",
    "        loss_np+=cls_loss_np\n",
    "    print('epoch %d : % d epochs loss %3.2f '% (epoch,cls_epochs,loss_np/batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_batch_size=2\n",
    "batchs=int(test_data.shape[0]/cls_batch_size)\n",
    "den=np.sum(test_labels,axis=0)\n",
    "num=np.zeros([1,10])\n",
    "for epoch in range(1):\n",
    "#     loss_np=0\n",
    "    corrects=0\n",
    "    for i in range(batchs):\n",
    "        batch_xs_input=test_data[i*cls_batch_size:(i+1)*cls_batch_size]\n",
    "        batch_xs_label=test_labels[i*cls_batch_size:(i+1)*cls_batch_size]\n",
    "        predicts= sess.run(logits,\n",
    "                                 feed_dict={x_hat: batch_xs_input,x_label:batch_xs_label,keep_prob : 1})\n",
    "        num+=np.sum(one_hot[np.argmax(batch_xs_label,axis=1)]*one_hot[np.argmax(predicts,axis=1)],axis=0)\n",
    "        corrects+=np.sum(np.argmax(predicts,axis=1)==np.argmax(batch_xs_label,axis=1))\n",
    "        #         loss_np+=cls_loss_np\n",
    "    print('acc %3.2f '% (corrects/batchs/cls_batch_size))\n",
    "    print('recall : ',num/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
